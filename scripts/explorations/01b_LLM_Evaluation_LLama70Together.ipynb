{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f74337-845b-49cc-86de-b12c60231cca",
   "metadata": {},
   "source": [
    "### Import Modules and Set up Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad9b837-3f8e-4310-9206-75c65e6dcd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81cfc788-bf49-4b37-b42a-c296afb30b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your API Key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key has been set for this session.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Prompt for the key without showing it on screen\n",
    "my_secret_key = getpass('Please enter your API Key: ')\n",
    "\n",
    "# Set it as an environment variable\n",
    "os.environ['TOGETHER_API_KEY'] = my_secret_key\n",
    "\n",
    "print(\"API Key has been set for this session.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23712085-2faa-4640-a235-0a7fb587a09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schmaelz/miniconda3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in BatchJob has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6"
     ]
    }
   ],
   "source": [
    "from together import Together\n",
    "\n",
    "client = Together()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Please evaluate the following transcript of a public science/research presentation. Assign a quality rating from 1 (worst) to 10 (best) based on your assessment. Return only a single rating number as a plain integer, with no other text or characters. Here is the speech text: \\\\ufeffSo this presentation was from a class presentation last year so if I don't remember any detail such as this is a little fuzzy.\\\\nI did actually go back and edit it a bit because I flipped it over and I saw something I didn't like anymore.\\\\nSo it's a little bit revised.\\\\nSo this is a presentation for a health-based bath called My Pantry.\\\\nSo here's what we'll be going over in this presentation.\\\\nSo audience interaction.\\\\nIt's an interaction here.\\\\nYou ever made just made ramen or order it out because you didn't feel like you had anything in the house.\\\\nAnd then so healthy eating is important no matter what you're trying to accomplish with your health.\\\\nBut this can be difficult to do with limited resources and if you don't really have a strong knowledge of cooking it can be a little intimidating to start.\\\\nThis app aims to provide recipes tailored to what you already have in your pantry.\\\\nAnd so if you're using up ingredients you’ve already have and improving skills at the same time.\\\\nSo the amount of healthy, unhealthy options that both adults and children eat on daily basis has increased.\\\\n92.7% of U.S. children in 6 to 8, 86.6% of U.S. adults say that they consume junk food on any given day.\\\\nAnd also in the U.S., 30 to 40% of the food supplies estimated to become food waste.\\\\nWe don't necessarily have one specific target audience but we aim at people with the desired to eat healthier and they also want to have new and creative ways to use up the food they’ve already had at home.\\\\nThis being said, there's also a prominent audience in younger people who are cooking on their own for the first time.\\\\nSo the goals of this app is to encourage healthy eating and an overall like healthier lifestyle to reduce food waste, to promote community environment, and also if desire to provide a fitness, a way to improve your fitness goals.\\\\nSo for the theoretical basis here, we're using the functional triad and the Fogg behavior model, providing trigger, motivation, and ability for the healthy eating.\\\\nHere is our app.\\\\nSeeing here, we have the log-in cage, because there's a social forum aspect to this.\\\\nYou would be required to make the user name and password.\\\\nWe have the recipes area that has different recipes.\\\\nThe main draw of this app is that you put in the food you already have into your pantry screen and it will generate recipes that use those foods.\\\\nIf you have chicken, carrots, and potatoes in your pantry and you don't know what to do with them, you could put in those foods and it would give you recipes that use those ingredients.\\\\nThere's also a way just to search for recipes without having to put in the ingredients.\\\\nThe user profile where you can save recipes as well as like star them so other people can see your ratings.\\\\nSo let's say you make a curry and you really like it so you get a five stars.\\\\nPeople who visit your profile can see that you gave it five stars.\\\\nHere's an example of a recipe.\\\\nIdeally they would be easy to follow and also if they include any more advanced terms or ideas they would give you an explanation of what those terms mean.\\\\nIn cooking there is especially like a western cooking.\\\\nThere's a lot of French terms and if you don't know what they mean it can be a little annoying to have to figure that out mid-recipe.\\\\nSo by giving an index of information it just helps with accessibility.\\\\nThe recipes also come with nutrition facts so you can see what you're eating and you can choose a recipe based on what you need.\\\\nThrough the fitness aspect they also include a health tracker.\\\\nThis is purely optional. You don't need to have this enabled in case you don't want to see the calories.\\\\nI know that's also an issue with unhealthy relationships with food, feeling that you have to track every calorie or be hyper aware of whatever you need.\\\\nThis is a purely optional portion that you can disable from the settings menu.\\\\nThere's also a meal prep planner which is just a calendar that you can use to plain ahead what meals you're going to have during the day.\\\\nThis is probably useful to do while making a grocery list so you can get the ready ingredients.\\\\nIt also will give you reminders of what you're planning to make that day.\\\\nI mentioned earlier that there's the index of important terms.\\\\nThis is just a glossary of any cooking terms or words or techniques that you might not be aware of.\\\\nWhen something says to simmer, it means very specifically leave on low heat for a little bit.\\\\nBut if you're here cooking you might not know that.\\\\nFor the community function we include a form. This is a model of a kind of a Reddit.\\\\nInstead of an Instagram feed it's more of a community form.\\\\nSomeone could open up a topic. It would be best vegetarian dishes and people could talk under that.\\\\nThere's also an opportunity for people to post pictures and what they created and for people to like it or favorite it or say the recipe they used.\\\\nThere's also the comments section. I knew these comments wouldn't be a little bit moderated so they could be a filter for the worst stuff.\\\\nAnother aspect of this.\\\\nAnother aspect of this is a community tagging system.\\\\nObviously with the nature of our search engine people are going to be looking up for specific keywords.\\\\nSince we're getting a lot of these recipes from other recipe sites on the internet they may not be possible to tag them all.\\\\nThe community tagging system is if someone sees a recipe and notices there isn't a correct tag they can submit that tag to it.\\\\nThere's a browny recipe and it is gluten free and that tag is not on there.\\\\nA user who makes it can realize that this is gluten free and it works for me.\\\\nI should add that gluten free tag. That way the community contributes to making the app more usable for everyone.\"\n",
    "      }\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "for token in response:\n",
    "    if hasattr(token, 'choices'):\n",
    "        print(token.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc16b27-d31b-4246-abf8-0fd1997f2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from together import Together\n",
    "\n",
    "client = Together() # auth defaults to os.environ.get(\"TOGETHER_API_KEY\")\n",
    "\n",
    "import os, requests, warnings, glob, re, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "\n",
    "def extract_first_integer(text):\n",
    "  \"\"\"Extracts the first integer from a string or returns the integer if already an int.\"\"\"\n",
    "  if isinstance(text, int):\n",
    "    return text\n",
    "  if isinstance(text, str):\n",
    "    match = re.search(r'\\d+', text)\n",
    "    if match:\n",
    "      return int(match.group(0))\n",
    "  return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368bff16-23e8-4fc3-890a-a8ee538d4ab1",
   "metadata": {},
   "source": [
    "### 1 Define Slices, Paths, and Instruction Prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2315d03e-105d-451c-9fd7-bb9b05bc468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [1.0, 0.75, 0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01]\n",
    "\n",
    "speech_transcript_folder = '../data/02_transcripts_corrected/'\n",
    "speech_appendix          = '_cut_corrected.txt'\n",
    "output_folder            = '../data/06_llm_ratings_2/'\n",
    "\n",
    "# Prompts\n",
    "# Prompt 1: Direct and Minimalist\n",
    "# Prompt 2: Emphasizing Holistic Quality\n",
    "# Prompt 3: Neutral and Instructional\n",
    "# Prompt 4: Framing as an Expert Evaluation\n",
    "# Prompt 5: Avoiding Explicit Criteria While Keeping the Task Clear\n",
    "instruct_prompt_list = [\"Here is a transcript from a public presentation on a science/research topic. Please rate the speech quality on a scale from 1 (worst) to 10 (best). Consider factors such as clarity, engagement, and how easy it is to follow. Return only the single rating number as a plain integer, with no other text or characters. Here is the speech text: \",\n",
    "                        \"You will receive a transcript of a science/research presentation. Rate the overall rhetorical quality on a scale from 1 (worst) to 10 (best), considering clarity, engagement, structure, and delivery. Return only the single rating number as a plain integer, with no other text or characters. Here is the speech text: \",\n",
    "                        \"Given the following transcript of a science/research presentation, assess its overall speech quality. Focus on aspects such as clarity, engagement, and coherence. Provide only a single numerical rating from 1 (worst) to 10 (best), without any additional text. Here is the speech text: \",\n",
    "                        \"Imagine you are an expert in public speaking evaluation. Below is a transcript from a science/research presentation. Please rate the effectiveness of the speech on a scale of 1 (worst) to 10 (best) based on clarity, engagement, and ease of understanding. Return only the single rating number as a plain integer, with no other text or characters. Here is the speech text: \",\n",
    "                        \"Please evaluate the following transcript of a public science/research presentation. Assign a quality rating from 1 (worst) to 10 (best) based on your assessment. Return only a single rating number as a plain integer, with no other text or characters. Here is the speech text: \"]\n",
    "num_instruction_prompts = len(instruct_prompt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ffaa0-4a1c-4dcc-a138-103a4b4aca19",
   "metadata": {},
   "source": [
    "### 2 Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce219969-4df0-421c-9f8f-5f02b04d7a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SUB001_SPEECH001', 'SUB002_SPEECH001', 'SUB003_SPEECH001']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df           = pd.read_csv('../data/list_of_subjects.csv')\n",
    "speech_names = list(df.name.values)\n",
    "num_speeches = len(speech_names)\n",
    "print(num_speeches)\n",
    "speech_names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469abe18-f1f3-4ef9-a469-7dfd9f98c226",
   "metadata": {},
   "source": [
    "### 3 Concept Prompt and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c4f3ec-e1f9-43fc-9a27-2d7a146a12c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Slice Length:\n",
      "1.0\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Slice Length:\n",
      "0.75\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Slice Length:\n",
      "0.5\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Slice Length:\n",
      "0.4\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Slice Length:\n",
      "0.3\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Slice Length:\n",
      "0.2\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Slice Length:\n",
      "0.1\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Slice Length:\n",
      "0.05\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Slice Length:\n",
      "0.01\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n",
      "Current Instruction Prompt:\n"
     ]
    }
   ],
   "source": [
    "# loop over slices\n",
    "\n",
    "lengths = []\n",
    "for curr_slice in slices: \n",
    "    print('Current Slice Length:')\n",
    "    print(curr_slice)\n",
    "\n",
    "    # loop over different prompting strategies\n",
    "    for curr_instruct_prompt_index in range(num_instruction_prompts):\n",
    "        print('Current Instruction Prompt:')\n",
    "        #print(curr_instruct_prompt_index)\n",
    "        curr_instruct_prompt_text = instruct_prompt_list[curr_instruct_prompt_index]\n",
    "    \n",
    "        # loop over the individual speeches\n",
    "        llama370b_names, llama370b_ratings = [], []\n",
    "        for curr_speech_name in speech_names:#[:1]:\n",
    "            #print(curr_speech_name)\n",
    "    \n",
    "            # read in the speech text and limit to the part defined by the slice length\n",
    "            input_text_file = speech_transcript_folder + curr_speech_name + speech_appendix\n",
    "            with open(input_text_file, \"r\", encoding=\"utf-8\") as file:\n",
    "                 content = file.read()\n",
    "            index = int(len(content)* curr_slice)\n",
    "            part_of_speech = content[0:index] \n",
    "            lengths.append(len(part_of_speech.split() ))\n",
    "\n",
    "            # create the full prompt to be submitted and submit to LLM\n",
    "            #\"\"\"\n",
    "            full_prompt = curr_instruct_prompt_text + part_of_speech\n",
    "                \n",
    "            # Ollama3.3 70b parameters\n",
    "            #response = ####ollama.chat(model='llama3', messages=[{'role': 'user','content': full_prompt,},])\n",
    "            response = client.chat.completions.create(model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",messages=[ { \"role\": \"user\",\"content\": full_prompt }])\n",
    "            #print(response.choices[0].message.content) \n",
    "            llm_response_llama370b  = response.choices[0].message.content #response.json()['choices'][0]['message']['content']\n",
    "            llama370b_names.append( str(curr_speech_name)) \n",
    "            llama370b_ratings.append(int(extract_first_integer(llm_response_llama370b)))\n",
    "        \n",
    "\n",
    "        df = pd.DataFrame({\"name\": llama370b_names, \"rating\": llama370b_ratings})        \n",
    "        out_name = output_folder + \"corrected_transcripts_llama3-70_slice#\" + str(curr_slice) + \"_prompt#\"  + str(curr_instruct_prompt_index + 1) +  \"_rating.csv\"\n",
    "        df.to_csv(out_name, index=False) #\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3e6037-1c4a-4354-b94c-883b4ffba99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493.24913194444446"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.asarray(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4eea4e-91fb-4285-9f60-30cb30715495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
